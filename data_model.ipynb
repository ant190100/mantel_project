{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6bbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# --- 0) (Re)load & preprocess Titanic so we still have X_test_df ---\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = (\n",
    "    sns.load_dataset(\"titanic\")\n",
    "       .loc[:, ['survived','pclass','sex','age','sibsp','parch','fare','embarked']]\n",
    "       .dropna()\n",
    ")\n",
    "X_df = pd.get_dummies(df.drop(columns='survived'),\n",
    "                      columns=['sex','embarked'],\n",
    "                      drop_first=True)\n",
    "y = df['survived'].values\n",
    "\n",
    "# keep feature names for SHAP\n",
    "feature_names = X_df.columns.tolist()\n",
    "\n",
    "# split *the DataFrame* so X_test_df stays a DataFrame\n",
    "X_train_df, X_test_df, y_train_np, y_test_np = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# scale the numeric arrays\n",
    "scaler     = StandardScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_df.values)\n",
    "X_test_np  = scaler.transform(X_test_df.values)\n",
    "\n",
    "# convert to torch\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.long)\n",
    "y_test  = torch.tensor(y_test_np, dtype=torch.long)\n",
    "\n",
    "# --- assume your TitanicNet() model is already defined & trained ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef1d8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 — loss: 0.6915\n",
      "Epoch 20/50 — loss: 0.6776\n",
      "Epoch 30/50 — loss: 0.6648\n",
      "Epoch 40/50 — loss: 0.6532\n",
      "Epoch 50/50 — loss: 0.6426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TitanicNet(\n",
       "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ───── define & train TitanicNet in a separate cell ─────\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1) define the ultra‐simple network\n",
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, 2)   # logistic regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 2) instantiate & send to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = TitanicNet(X_train.shape[1]).to(device)\n",
    "\n",
    "# 3) set up optimizer + loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4) training loop\n",
    "n_epochs = 50\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_train.to(device))\n",
    "    loss   = loss_fn(logits, y_train.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{n_epochs} — loss: {loss.item():.4f}\")\n",
    "\n",
    "# 5) switch to eval mode before SHAP\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ff7834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b000754a53e4815bf5c465bb43af9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Passenger', max=142), IntSlider(value=100, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 1) build a KernelExplainer on the scaled training set ---\n",
    "bg_np = X_train[:50].cpu().numpy()\n",
    "\n",
    "def model_np(x_array):\n",
    "    t = torch.tensor(x_array, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(model(t), dim=1).cpu().numpy()\n",
    "    return probs[:,1]   # return P(survived)\n",
    "\n",
    "explainer = shap.KernelExplainer(model_np, bg_np)\n",
    "\n",
    "# --- 2) updated explain_sample that shows raw values + SHAP ---\n",
    "def explain_sample(idx, nsamples=100, max_display=10):\n",
    "    # raw unscaled Series\n",
    "    raw_row = X_test_df.iloc[idx]\n",
    "    display(raw_row.to_frame(name=\"value\"))\n",
    "    \n",
    "    # scaled array for SHAP & model\n",
    "    x_np = X_test[idx].cpu().numpy().reshape(1, -1)\n",
    "\n",
    "    # model probs\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(x_np, dtype=torch.float32, device=device))\n",
    "        probs  = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    print(\n",
    "        f\"Passenger {idx}: true={'survived' if y_test[idx]==1 else 'died'}  \"\n",
    "        f\"p(died)={probs[0]:.3f}, p(survived)={probs[1]:.3f}\\n\"\n",
    "    )\n",
    "\n",
    "    # SHAP values\n",
    "    raw_sv = explainer.shap_values(x_np, nsamples=nsamples)\n",
    "    sv     = raw_sv[0]\n",
    "    bv     = explainer.expected_value\n",
    "\n",
    "    # package & plot\n",
    "    exp = shap.Explanation(\n",
    "        values=sv,\n",
    "        base_values=bv,\n",
    "        data=x_np[0],\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "    shap.initjs()\n",
    "    shap.plots.waterfall(exp, max_display=max_display)\n",
    "\n",
    "# --- 3) interactive slider ---\n",
    "interact(\n",
    "    explain_sample,\n",
    "    idx=IntSlider(min=0, max=len(X_test_df)-1, step=1, value=0, description=\"Passenger\"),\n",
    "    nsamples=IntSlider(min=10, max=500, step=10, value=100, description=\"MC samps\"),\n",
    "    max_display=IntSlider(min=1, max=len(feature_names), step=1, value=10, description=\"Top feat\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32eade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb271ae30cf4e5cb53bd5699659f334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Pclass', index=2, options=(1, 2, 3), value=3), Dropdown(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.simulate_scenario(pclass, sex, age, sibsp, parch, fare, embarked, nsamples=100, max_display=10)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4) interactive What-If Scenario Simulator ---\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Dropdown\n",
    "import shap\n",
    "\n",
    "# Pre-compute allowed values for dropdowns\n",
    "pclass_opts   = [1, 2, 3]\n",
    "sex_opts      = ['female', 'male']\n",
    "embarked_opts = ['C', 'Q', 'S']\n",
    "\n",
    "def simulate_scenario(pclass, sex, age, sibsp, parch, fare, embarked,\n",
    "                      nsamples=100, max_display=10):\n",
    "    # 1) Build raw input dict\n",
    "    raw = {\n",
    "        'pclass': pclass,\n",
    "        'age': age,\n",
    "        'sibsp': sibsp,\n",
    "        'parch': parch,\n",
    "        'fare': fare,\n",
    "        # one-hot encoding\n",
    "        'sex_male': 1 if sex == 'male' else 0,\n",
    "        'embarked_Q': 1 if embarked == 'Q' else 0,\n",
    "        'embarked_S': 1 if embarked == 'S' else 0,\n",
    "    }\n",
    "    raw_df = pd.DataFrame([raw])\n",
    "    display(raw_df.T.rename(columns={0: 'value'}))\n",
    "    \n",
    "    # 2) Scale numeric features & assemble numpy row\n",
    "    # Note: scaler expects columns in original order\n",
    "    X_row = raw_df[feature_names].values\n",
    "    X_scaled = scaler.transform(X_row)\n",
    "    \n",
    "    # 3) Predict\n",
    "    probs = model_np(X_scaled)[0]\n",
    "    print(f\"Custom scenario — p(died)={1-probs:.3f}, p(survived)={probs:.3f}\\n\")\n",
    "    \n",
    "    # 4) SHAP explanation\n",
    "    sv  = explainer.shap_values(X_scaled, nsamples=nsamples)[0]\n",
    "    bv  = explainer.expected_value\n",
    "    exp = shap.Explanation(\n",
    "        values=sv,\n",
    "        base_values=bv,\n",
    "        data=X_scaled[0],\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "    shap.initjs()\n",
    "    shap.plots.waterfall(exp, max_display=max_display)\n",
    "\n",
    "# 5) Launch the UI\n",
    "interact(\n",
    "    simulate_scenario,\n",
    "    pclass   = Dropdown(options=pclass_opts, value=3, description='Pclass'),\n",
    "    sex      = Dropdown(options=sex_opts,    value='male', description='Sex'),\n",
    "    age      = FloatSlider(min=0, max=80,    step=0.5, value=30, description='Age'),\n",
    "    sibsp    = IntSlider(min=0, max=5,       step=1,   value=0,  description='SibSp'),\n",
    "    parch    = IntSlider(min=0, max=5,       step=1,   value=0,  description='ParCh'),\n",
    "    fare     = FloatSlider(min=0, max=300,   step=1,   value=32, description='Fare'),\n",
    "    embarked = Dropdown(options=embarked_opts,value='S',   description='Embarked'),\n",
    "    nsamples = IntSlider(min=10, max=500,    step=10,  value=100, description='MC samps'),\n",
    "    max_display = IntSlider(min=1, max=len(feature_names), step=1, value=10, description='Top feat')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "926b6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch, shap, pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()        # make sure we’re in eval mode\n",
    "\n",
    "def predict_df(data):\n",
    "    \"\"\"\n",
    "    Accepts either a pandas DataFrame or NumPy array,\n",
    "    returns model outputs as a NumPy array.\n",
    "    \"\"\"\n",
    "    # 1. Convert to ndarray (pandas → ndarray is zero-copy)\n",
    "    arr = np.asarray(data, dtype=np.float32)\n",
    "\n",
    "    # 2. Torch forward pass\n",
    "    with torch.no_grad():\n",
    "        x_t = torch.from_numpy(arr).to(device)\n",
    "        y   = model(x_t).cpu().numpy()\n",
    "\n",
    "    return y                  # shape (batch, outputs)\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# ── 1️⃣  Build explainer with ANY small background sample ───────────────\n",
    "background = X_train_df.sample(100, random_state=42)   # still a DataFrame\n",
    "explainer  = shap.Explainer(predict_df, background)    # auto-picks Kernel/Exact\n",
    "\n",
    "# ── 2️⃣  Compute SHAP for ONE row (fast) ────────────────────────────────\n",
    "row      = 0\n",
    "shap_1d  = explainer(X_test_df.iloc[[row]]).values[0]  # 1-D SHAP vector\n",
    "\n",
    "# If SHAP gives extra positions, trim to real features\n",
    "shap_1d = shap_1d[: len(X_test_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je me passionne pour la machine learning.\n"
     ]
    }
   ],
   "source": [
    "api_key  = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e116526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║  🌐  SHAP-to-Narrative helper driven by HF chat-completion endpoint  ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "from huggingface_hub import InferenceClient\n",
    "import numpy as np, textwrap, os\n",
    "\n",
    "# 1️⃣  Build ONE global chat client (reuse for every call)\n",
    "HF_MODEL   = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"        # TGI-hosted, fast, ~2 B params\n",
    "HF_CLIENT  = InferenceClient(\n",
    "    model  = HF_MODEL,\n",
    "    # token picked up from $HUGGINGFACEHUB_API_TOKEN or passed explicitly\n",
    "    timeout=45,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def explain_with_citations(\n",
    "    shap_values,\n",
    "    x_row,\n",
    "    feature_names,\n",
    "    target_name=\"prediction\",\n",
    "    top_k=5,\n",
    "    temperature=0.4,\n",
    "    max_new_tokens=160,\n",
    "):\n",
    "    \"\"\"\n",
    "    Return a plain-English explanation with inline [n] citations,\n",
    "    explicitly telling the LLM what each feature is called.\n",
    "    \"\"\"\n",
    "    # 1️⃣ align and coerce\n",
    "    shap_arr = np.asarray(shap_values, dtype=float).ravel()\n",
    "    n        = min(len(shap_arr), len(feature_names), len(x_row))\n",
    "    shap_arr, feature_names, x_row = shap_arr[:n], feature_names[:n], x_row[:n]\n",
    "\n",
    "    # 2️⃣ select top-k by absolute impact\n",
    "    idx_sorted = np.argsort(np.abs(shap_arr))[::-1][:top_k]\n",
    "\n",
    "    # 3️⃣ build fact block with *names* and SHAP numbers\n",
    "    context = \"\\n\".join(\n",
    "        f\"[{i}] **{feature_names[idx]}** = {x_row[idx]} \"\n",
    "        f\"(SHAP {shap_arr[idx]:+.3f})\"\n",
    "        for i, idx in enumerate(idx_sorted, 1)\n",
    "    )\n",
    "\n",
    "    # 4️⃣ chat messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an assistant that explains machine-learning predictions \"\n",
    "                \"to non-technical business stakeholders. When referencing a feature, \"\n",
    "                \"use the exact bold-face name provided in the facts.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": textwrap.dedent(\n",
    "                f\"\"\"\\\n",
    "                Below are the most influential features for one sample and their SHAP contributions.\n",
    "                • Write 3–4 plain-English sentences that explain **why** the model arrived at the\n",
    "                  current {target_name}.\n",
    "                • Whenever you reference a feature, copy its bold name and append the citation key\n",
    "                  (e.g. **Age** [1]).\n",
    "                • Do **not** invent any information beyond the facts block.\n",
    "\n",
    "                ### Facts\n",
    "                {context}\n",
    "                \"\"\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    resp = HF_CLIENT.chat.completions.create(\n",
    "        model        = HF_MODEL,\n",
    "        messages     = messages,\n",
    "        temperature  = temperature,\n",
    "        max_tokens   = max_new_tokens,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c9f32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To explain why the model arrived at the current prediction, we can reference the Age feature. The Age feature has a bold name of \"Age\" and was included in the facts block. When referencing this feature, we can simply append the citation key (e.g. Age [1]). This will ensure that the feature is properly cited and referenced in the explanation.\n",
      "\n",
      "Furthermore, the SHAP (Shapley Additive Explanations) methodology is used to generate SHAP values for each feature. SHAP values are calculated based on the relationship between the feature and the predicted output. The SHAP value for Age is -0.025, which indicates a 25% decrease in the predicted output when Age is included.\n",
      "\n",
      "Overall\n"
     ]
    }
   ],
   "source": [
    "row = 0\n",
    "narrative = explain_with_citations(\n",
    "    shap_values   = shap_1d[row],        # 1-D SHAP vector\n",
    "    x_row         = X_test_df.iloc[row].values,\n",
    "    feature_names = X_test_df.columns\n",
    ")\n",
    "print(narrative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66648d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3e2d1c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.9918402' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1.01137768' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.96213639' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.06016502' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.23038878' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.13682646' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.87602218' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dice_ml/explainer_interfaces/dice_random.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.984578' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  candidate_cfs.at[k, selected_features[k][0]] = random_instances.at[k, selected_features[k][0]]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>y_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.292442</td>\n",
       "      <td>0.171672</td>\n",
       "      <td>-0.542897</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.418831</td>\n",
       "      <td>-1.327455</td>\n",
       "      <td>-0.195758</td>\n",
       "      <td>0.506034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2       f3        f4        f5        f6  \\\n",
       "0 -0.292442  0.171672 -0.542897 -0.50769 -0.418831 -1.327455 -0.195758   \n",
       "\n",
       "         f7  y_dummy  \n",
       "0  0.506034        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>y_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16363489627838135</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2.0591988563537598</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2.3166887760162354</td>\n",
       "      <td>9.01814079284668</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4.277249813079834</td>\n",
       "      <td>5.619028091430664</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f0 f1 f2                  f3                  f4 f5 f6 f7  \\\n",
       "0  0.16363489627838135  -  -                   -  2.0591988563537598  -  -  -   \n",
       "1                    -  -  -  2.3166887760162354    9.01814079284668  -  -  -   \n",
       "2                    -  -  -   4.277249813079834   5.619028091430664  -  -  -   \n",
       "\n",
       "  y_dummy  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ╔════════════════════════════════════════════════════════════════════╗\n",
    "# ║  ⚡ One-cell DiCE counterfactuals – PyTorch model, Python ≥ 3.12   ║\n",
    "# ╚════════════════════════════════════════════════════════════════════╝\n",
    "!pip install -qU \"dice-ml>=0.11.0\"   # one-time upgrade; no TensorFlow needed\n",
    "\n",
    "import numpy as np, pandas as pd, torch, dice_ml\n",
    "from IPython.display import display\n",
    "\n",
    "# ── 1️⃣  Torch → scikit-like wrapper (binary classifier) ──────────────\n",
    "class TorchWrapper:\n",
    "    def __init__(self, net, thresh=0.5):\n",
    "        self.net, self.thresh = net.eval(), thresh\n",
    "        self.dev = next(net.parameters()).device\n",
    "\n",
    "    def _forward(self, X):\n",
    "        if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "            X = X.to_numpy()\n",
    "        X = torch.as_tensor(X, dtype=torch.float32, device=self.dev)\n",
    "        with torch.no_grad():\n",
    "            return self.net(X).cpu().numpy()          # (n, n_out)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        logits = self._forward(X)\n",
    "        if logits.shape[1] == 1:                      # sigmoid\n",
    "            p1 = 1 / (1 + np.exp(-logits.ravel()))\n",
    "            return np.column_stack([1 - p1, p1])\n",
    "        exp = np.exp(logits - logits.max(1, keepdims=True))\n",
    "        return exp / exp.sum(1, keepdims=True)       # softmax\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= self.thresh).astype(int)\n",
    "\n",
    "wrapped = TorchWrapper(model)        # ← your trained TitanicNet\n",
    "\n",
    "# ── 2️⃣  Build Data & Model interfaces for DiCE ───────────────────────\n",
    "train_df = X_train_df.copy()\n",
    "train_df[\"y_dummy\"] = wrapped.predict(train_df)      # dummy outcome column\n",
    "\n",
    "categorical = [c for c in train_df if train_df[c].dtype == \"object\"]\n",
    "continuous  = [c for c in train_df if c not in categorical + [\"y_dummy\"]]\n",
    "\n",
    "data_dice = dice_ml.Data(\n",
    "    dataframe           = train_df,\n",
    "    continuous_features = continuous,\n",
    "    categorical_features= categorical,\n",
    "    outcome_name        = \"y_dummy\",\n",
    ")\n",
    "model_dice = dice_ml.Model(model=wrapped, backend=\"sklearn\")  # ✅ no TF import\n",
    "dice_engine = dice_ml.Dice(data_dice, model_dice, method=\"random\")\n",
    "\n",
    "# ── 3️⃣  Helper: view k counterfactuals for any test row ──────────────\n",
    "def dice_cf(row_idx: int = 0, k: int = 3):\n",
    "    query_df = X_test_df.iloc[[row_idx]]            # DataFrame keeps .columns\n",
    "    cf = dice_engine.generate_counterfactuals(\n",
    "        query_instances = query_df,\n",
    "        total_CFs       = k,\n",
    "        desired_class   = \"opposite\",\n",
    "        proximity_weight= 1.0,\n",
    "        diversity_weight= 0.0,\n",
    "        verbose         = False\n",
    "    )\n",
    "    display(cf.visualize_as_dataframe(show_only_changes=True))\n",
    "\n",
    "# ── 4️⃣  Example run ───────────────────────────────────────────────────\n",
    "dice_cf(0, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4547870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
